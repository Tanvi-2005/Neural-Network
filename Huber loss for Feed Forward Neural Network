import numpy as np

# Huber Loss Function
def huber_loss(y, y_pred, delta=1.0):
    error = y - y_pred
    if abs(error) <= delta:
        return 0.5 * error**2
    else:
        return delta * (abs(error) - 0.5 * delta)

# Forward Pass Function
def forward_pass(x, W1, b1, W2, b2):
    # Hidden layer
    z1 = np.dot(x, W1) + b1
    a1 = np.maximum(0, z1)   # ReLU activation
    
    # Output layer
    y_pred = np.dot(a1, W2) + b2
    return y_pred, a1

# Input (10 features)
x = np.array([1.2, 0.5, 2.1, 3.3, 0.7, 1.8, 2.9, 0.4, 1.1, 2.0])
y = 15.0   # True value


# Initialize Weights
np.random.seed(42)

W1 = np.random.randn(10, 5)   # 10 inputs → 5 hidden neurons
b1 = np.zeros(5)

W2 = np.random.randn(5, 1)    # 5 hidden → 1 output
b2 = 0.0

# Forward Pass
y_pred, hidden_output = forward_pass(x, W1, b1, W2, b2)
y_pred = y_pred[0]

# Loss Calculation
loss = huber_loss(y, y_pred, delta=1.0)

# Output
print("Predicted Output:", y_pred)
print("True Output:", y)
print("Huber Loss:", loss)
